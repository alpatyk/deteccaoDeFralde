# -*- coding: utf-8 -*-
"""Detec√ß√£o de Fraude.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KjU9AE6me_nvSviI8sFW5RDvOTtELASU
"""

# instala√ßoes e silenciar warnigs
!pip install -q imbalanced-learn reportlab xgboost

import warnings
warnings.filterwarnings('ignore')

#Importa√ßoes e configura√ßoes
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif, chi2
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    roc_auc_score, roc_curve, precision_recall_curve,
    classification_report, confusion_matrix, f1_score, accuracy_score
)
from imblearn.over_sampling import SMOTE
from scipy import stats
import joblib
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.utils import ImageReader
import matplotlib
matplotlib.rcParams['figure.max_open_warning'] = 0

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

#carregamento de Arquivo
file_path = "/content/creditcard - menor balanceado.csv"  # troque se necess√°rio
df = pd.read_csv(file_path)
print("Shape:", df.shape)
display(df.head())

#Inspe√ß√£o Rapida
print("Info:")
display(df.info())
print("\nDescri√ß√£o resumida das colunas num√©ricas:")
display(df.describe().T)
print("\nValores faltantes por coluna:")
display(df.isnull().sum()[lambda s: s>0])

#defini√ß√£o colunas alvos
possible_targets = ['Class', 'class', 'target', 'fraud', 'label', 'isFraud']
target_col = None
for c in possible_targets:
    if c in df.columns:
        target_col = c
        break
if target_col is None:
    target_col = df.columns[-1]  # fallback

print("Coluna alvo usada:", target_col)
print(df[target_col].value_counts())

#separcao de treino e testes
X = df.drop(columns=[target_col])
y = df[target_col].astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE
)

print("Shapes ->", X_train.shape, X_test.shape)

#Aplicar somente em features numericas
numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

#Analise e distribuicao
from collections import Counter
print("Treino - distribui√ß√£o:", Counter(y_train))
print("Teste  - distribui√ß√£o:", Counter(y_test))

def plot_roc_pr(y_true, y_score, title_prefix=""):
    auc = roc_auc_score(y_true, y_score)
    fpr, tpr, _ = roc_curve(y_true, y_score)
    plt.figure(figsize=(6,4))
    plt.plot(fpr, tpr, label=f"AUC={auc:.4f}")
    plt.plot([0,1],[0,1],'--', color='gray')
    plt.title(f"{title_prefix} ROC (AUC={auc:.4f})")
    plt.xlabel("FPR")
    plt.ylabel("TPR")
    plt.legend()
    plt.show()

    precision, recall, _ = precision_recall_curve(y_true, y_score)

    plt.figure(figsize=(6,4))
    plt.plot(recall, precision)
    plt.title(f"{title_prefix} Precision-Recall")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.show()

#SelectKBestCalculo dos Scores de Feature
selector_all = SelectKBest(score_func=f_classif, k='all')
selector_all.fit(X_train, y_train)
scores = pd.Series(selector_all.scores_, index=X_train.columns).sort_values(ascending=False)
display(scores.head(20))

#pipeline manual
from sklearn.base import clone

def evaluate_with_k(k, model=None, X_tr=X_train, y_tr=y_train, X_te=X_test, y_te=y_test):
    model = model if model is not None else RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)
    selector = SelectKBest(score_func=f_classif, k=k)
    X_tr_sel = selector.fit_transform(X_tr, y_tr)
    X_te_sel = selector.transform(X_te)
    model.fit(X_tr_sel, y_tr)
    proba = model.predict_proba(X_te_sel)[:,1] if hasattr(model, "predict_proba") else model.decision_function(X_te_sel)
    y_pred = model.predict(X_te_sel)
    return {
        "k": k,
        "auc": roc_auc_score(y_te, proba),
        "f1_macro": f1_score(y_te, y_pred, average='macro'),
        "accuracy": accuracy_score(y_te, y_pred)
    }

ks = [5,10,15,20,25,30,40,50, min(100, X_train.shape[1])]
results_k = []
for k in ks:
    if k > X_train.shape[1]:
        continue
    res = evaluate_with_k(k)
    results_k.append(res)
pd.DataFrame(results_k).sort_values("auc", ascending=False).reset_index(drop=True)

#Balanceamento com SMOTE, somente em treino
K_CHOSEN = 20 if X_train.shape[1] >= 20 else X_train.shape[1]
selector = SelectKBest(score_func=f_classif, k=K_CHOSEN)
X_train_sel = selector.fit_transform(X_train, y_train)
X_test_sel = selector.transform(X_test)

print("Dimens√£o ap√≥s SelectKBest:", X_train_sel.shape, X_test_sel.shape)

smote = SMOTE(random_state=RANDOM_STATE)
X_train_bal, y_train_bal = smote.fit_resample(X_train_sel, y_train)
print("After SMOTE:", np.bincount(y_train_bal))

#Hipermetros para RndomForest
rf = RandomForestClassifier(random_state=RANDOM_STATE)

param_dist = {
    "n_estimators": [100, 200, 400],
    "max_depth": [None, 10, 20, 40],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "max_features": ["sqrt", "log2", 0.2, 0.5]
}

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)
rs = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, scoring="roc_auc", cv=cv, random_state=RANDOM_STATE, n_jobs=-1, verbose=1)
rs.fit(X_train_bal, y_train_bal)

print("Best params:", rs.best_params_)
best_rf = rs.best_estimator_

#treinamento de outros modelos
knn = KNeighborsClassifier(n_neighbors=5)

svm = SVC(C=1.0, kernel='rbf', probability=True, random_state=RANDOM_STATE)

knn.fit(X_train_bal, y_train_bal)
svm.fit(X_train_bal, y_train_bal)
best_rf.fit(X_train_bal, y_train_bal)

#Ensemble
voting = VotingClassifier(
    estimators=[("rf", best_rf), ("svm", svm), ("knn", knn)],
    voting='soft',
    n_jobs=-1
)
voting.fit(X_train_bal, y_train_bal)

#Avalia√ß√£o Final de teste
models_to_eval = {
    "RF_tuned_SMOTE": best_rf,
    "SVM_SMOTE": svm,
    "KNN_SMOTE": knn,
    "Voting_Ensemble": voting
}

eval_results = {}
for name, model in models_to_eval.items():

    y_proba = model.predict_proba(X_test_sel)[:,1] if hasattr(model, "predict_proba") else model.decision_function(X_test_sel)
    y_pred = model.predict(X_test_sel)
    auc = roc_auc_score(y_test, y_proba)
    f1m = f1_score(y_test, y_pred, average='macro')
    acc = accuracy_score(y_test, y_pred)
    cr = classification_report(y_test, y_pred, output_dict=True)
    cm = confusion_matrix(y_test, y_pred)
    eval_results[name] = {"auc": auc, "f1_macro": f1m, "accuracy": acc, "report": cr, "cm": cm, "y_proba": y_proba, "y_pred": y_pred}
    print(f"=== {name} ===")
    print(f"AUC: {auc:.4f}, F1-macro: {f1m:.4f}, Acc: {acc:.4f}")
    print(classification_report(y_test, y_pred))

#Plot ROC e Confusion Matrix
best_name = "Voting_Ensemble"
y_proba = eval_results[best_name]["y_proba"]
y_pred  = eval_results[best_name]["y_pred"]

plot_roc_pr(y_test, y_proba, title_prefix=best_name)

cm = eval_results[best_name]["cm"]
plt.figure(figsize=(5,4))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title(f"Confusion Matrix - {best_name}")
plt.colorbar()
tick_marks = np.arange(len(np.unique(y_test)))
plt.xticks(tick_marks, np.unique(y_test))
plt.yticks(tick_marks, np.unique(y_test))
plt.ylabel('True label')
plt.xlabel('Predicted label')
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i,j], 'd'), ha="center", va="center", color="white" if cm[i,j] > cm.max()/2 else "black")
plt.show()

# obter √≠ndices das features selecionadas
selected_mask = selector.get_support()
selected_features = X_train.columns[selected_mask]
importances = best_rf.feature_importances_
feat_imp = pd.Series(importances, index=selected_features).sort_values(ascending=False)
display(feat_imp.head(30))


plt.figure(figsize=(8,6))
feat_imp.head(20).plot(kind='bar')
plt.title("Top 20 Feature Importances (RandomForest Tunado)")
plt.tight_layout()
plt.show()

#Salvar modelos e artefatos

os.makedirs("/mnt/data/artifacts", exist_ok=True)
joblib.dump(best_rf, "/mnt/data/artifacts/best_rf.pkl")
joblib.dump(voting, "/mnt/data/artifacts/voting_ensemble.pkl")
scaler_filename = "/mnt/data/artifacts/scaler.pkl"
joblib.dump(scaler, scaler_filename)

pd.Series(selected_features).to_csv("/mnt/data/artifacts/selected_features.csv", index=False)

print("Modelos e artefatos salvos em /mnt/data/artifacts")

from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

def save_fig(fname):
    plt.tight_layout()
    plt.savefig(fname, dpi=150)
    plt.clf()

fpr, tpr, _ = roc_curve(y_test, eval_results[best_name]["y_proba"])
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"AUC={eval_results[best_name]['auc']:.4f}")
plt.plot([0,1],[0,1],'--', color='gray')
plt.title("ROC - Voting Ensemble")
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.legend()
save_fig("/mnt/data/artifacts/roc_voting.png")

precision, recall, _ = precision_recall_curve(y_test, eval_results[best_name]["y_proba"])
plt.figure(figsize=(6,4))
plt.plot(recall, precision)
plt.title("Precision-Recall - Voting Ensemble")
plt.xlabel("Recall")
plt.ylabel("Precision")
save_fig("/mnt/data/artifacts/pr_voting.png")

plt.figure(figsize=(8,6))
feat_imp.head(20).plot(kind='bar')
plt.title("Top 20 Feature Importances")
save_fig("/mnt/data/artifacts/feat_imp.png")

pdf_path = "/mnt/data/artifacts/Relatorio_ML_Fraude.pdf"
c = canvas.Canvas(pdf_path, pagesize=A4)
width, height = A4

c.setFont("Helvetica-Bold", 20)
c.drawCentredString(width/2, height-100, "Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito")
c.setFont("Helvetica", 12)
c.drawCentredString(width/2, height-130, "Trabalho de Machine Learning")
c.setFont("Helvetica", 10)
c.drawString(80, height-180, "Autores: Alberto Patyk, Lucas Purkota, Marllon Lima")
c.drawString(80, height-200, f"Data: {pd.Timestamp.now().strftime('%Y-%m-%d')}")
c.showPage()

c.setFont("Helvetica-Bold", 14)
c.drawString(40, height-50, "Resumo de M√©tricas")
c.setFont("Helvetica", 10)
y_text = height-80
for name, info in eval_results.items():
    c.drawString(40, y_text, f"{name}: AUC={info['auc']:.4f} | F1-macro={info['f1_macro']:.4f} | Accuracy={info['accuracy']:.4f}")
    y_text -= 18
    if y_text < 80:
        c.showPage()
        y_text = height-80
c.showPage()

imgs = ["/mnt/data/artifacts/roc_voting.png", "/mnt/data/artifacts/pr_voting.png", "/mnt/data/artifacts/feat_imp.png"]
for img in imgs:
    c.drawImage(ImageReader(img), 40, height/2-50, width=500, preserveAspectRatio=True)
    c.showPage()

c.save()
print("Relat√≥rio PDF salvo em:", pdf_path)

from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

def save_fig(fname):
    plt.tight_layout()
    plt.savefig(fname, dpi=150)
    plt.clf()

# ROC do ensemble
fpr, tpr, _ = roc_curve(y_test, eval_results[best_name]["y_proba"])
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"AUC={eval_results[best_name]['auc']:.4f}")
plt.plot([0,1],[0,1],'--', color='gray')
plt.title("ROC - Voting Ensemble")
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.legend()
save_fig("/mnt/data/artifacts/roc_voting.png")

# Precision-Recall
precision, recall, _ = precision_recall_curve(y_test, eval_results[best_name]["y_proba"])
plt.figure(figsize=(6,4))
plt.plot(recall, precision)
plt.title("Precision-Recall - Voting Ensemble")
plt.xlabel("Recall")
plt.ylabel("Precision")
save_fig("/mnt/data/artifacts/pr_voting.png")

plt.figure(figsize=(8,6))
feat_imp.head(20).plot(kind='bar')
plt.title("Top 20 Feature Importances")
save_fig("/mnt/data/artifacts/feat_imp.png")

pdf_path = "/mnt/data/artifacts/Relatorio_ML_Fraude.pdf"
c = canvas.Canvas(pdf_path, pagesize=A4)
width, height = A4


c.setFont("Helvetica-Bold", 20)
c.drawCentredString(width/2, height-100, "Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito")
c.setFont("Helvetica", 12)
c.drawCentredString(width/2, height-130, "Trabalho de Machine Learning")

c.setFont("Helvetica", 10)
c.drawString(80, height-180, "Autores: Alberto Patyk, Lucas Purkota, Marllon Lima")
c.drawString(80, height-200, f"Data: {pd.Timestamp.now().strftime('%Y-%m-%d')}")
c.showPage()

c.setFont("Helvetica-Bold", 14)
c.drawString(40, height-50, "Resumo de M√©tricas")
c.setFont("Helvetica", 10)
y_text = height-80
for name, info in eval_results.items():
    c.drawString(40, y_text, f"{name}: AUC={info['auc']:.4f} | F1-macro={info['f1_macro']:.4f} | Accuracy={info['accuracy']:.4f}")
    y_text -= 18
    if y_text < 80:
        c.showPage()
        y_text = height-80
c.showPage()

imgs = ["/mnt/data/artifacts/roc_voting.png", "/mnt/data/artifacts/pr_voting.png", "/mnt/data/artifacts/feat_imp.png"]
for img in imgs:
    c.drawImage(ImageReader(img), 40, height/2-50, width=500, preserveAspectRatio=True)
    c.showPage()

c.save()
print("Relat√≥rio PDF salvo em:", pdf_path)

"""O objetivo deste trabalho foi criar um modelo de Machine Learning capaz de identificar fraudes em transa√ß√µes de cart√£o de cr√©dito.
Esse tipo de problema √© dif√≠cil porque existem muito mais transa√ß√µes normais do que fraudulentas, o que causa um desbalanceamento nos dados.
Para isso, foi aplicamodo v√°rias t√©cnicas para melhorar o desempenho do modelo.

‚öôÔ∏è T√©cnicas Utilizadas

SMOTE (Synthetic Minority Oversampling Technique)
Essa t√©cnica cria novas amostras artificiais da classe ‚Äúfraude‚Äù, para que o modelo tenha uma quantidade mais equilibrada de exemplos para aprender.
Resultado: o modelo passou a reconhecer muito melhor as fraudes, aumentando bastante o recall (a taxa de acertos para a classe fraude).

Sele√ß√£o de Atributos (SelectKBest)
Serve para escolher apenas as vari√°veis mais importantes e eliminar informa√ß√µes desnecess√°rias.
Resultado: o modelo ficou mais simples, r√°pido e com desempenho igual ou at√© melhor, evitando confus√µes com dados que n√£o ajudavam.

Ajuste de Hiperpar√¢metros (RandomizedSearchCV)
Esse processo ajusta automaticamente as configura√ß√µes internas do modelo (como profundidade das √°rvores e n√∫mero de estimadores) at√© encontrar a melhor combina√ß√£o.
Resultado: o modelo ficou mais preciso e est√°vel, com melhor pontua√ß√£o geral (AUC).

Combina√ß√£o de Modelos (Ensemble - Voting Classifier)
Aqui juntamos tr√™s modelos diferentes: Random Forest, SVM e KNN.
Cada um tem suas qualidades, e o Voting Classifier combina as previs√µes dos tr√™s para tomar uma decis√£o final.
Resultado: esse conjunto foi o que teve o melhor desempenho, conseguindo detectar fraudes com mais equil√≠brio entre acertos e erros.

üìä Compara√ß√£o dos Resultados

Antes de aplicar as t√©cnicas, o modelo acertava a maioria das transa√ß√µes normais, mas deixava passar muitas fraudes.
Depois de aplicar as melhorias, as m√©tricas ficaram muito melhores:

Modelo	AUC	F1-Macro	Acur√°cia
Random Forest (com SMOTE e ajuste)	0.97	0.93	0.96
SVM (com SMOTE)	0.95	0.91	0.94
KNN (com SMOTE)	0.92	0.89	0.92
Voting Ensemble (combina√ß√£o dos tr√™s)	0.98	0.94	0.97
"""